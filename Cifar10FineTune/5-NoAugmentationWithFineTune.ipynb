{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v6_HIzjNQalA",
        "outputId": "91626e17-ba26-4952-ce50-6be5e1475908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-mhm5hvu9\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-mhm5hvu9\n",
            "  Resolved https://github.com/openai/CLIP.git to commit 3702849800aa56e2223035bccd1c6ef91c704ca8\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (4.64.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from clip==1.0) (0.14.1+cu116)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy->clip==1.0) (0.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->clip==1.0) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision->clip==1.0) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision->clip==1.0) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vEIquVGASMmG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "import os\n",
        "import torchvision\n",
        "import tarfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gP3UEOPdSPZm"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck2p0xSfSR0m",
        "outputId": "2da20d75-7862-40a5-e7a7-0e231ecedd1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VisionTransformer(\n",
              "  (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "  (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (transformer): Transformer(\n",
              "    (resblocks): Sequential(\n",
              "      (0): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (1): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (2): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (3): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (4): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (5): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (6): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (7): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (8): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (9): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (10): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (11): ResidualAttentionBlock(\n",
              "        (attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Sequential(\n",
              "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (gelu): QuickGELU()\n",
              "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "clip_model.visual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68s35u43SmdI",
        "outputId": "90e0d4ac-af4e-491b-a2fc-30324b98fee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./cifar10.tgz\n"
          ]
        }
      ],
      "source": [
        "# Dowload the dataset\n",
        "dataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\n",
        "download_url(dataset_url, '.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WvZmyfw6XzVP"
      },
      "outputs": [],
      "source": [
        "with tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n",
        "    tar.extractall(path='./data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-WCX8K3X6cp",
        "outputId": "027ab451-062d-4f00-b77f-8e464860025a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45000, 5000)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data_dir = './data/cifar10'\n",
        "dataset = ImageFolder(data_dir+'/train', transform=ToTensor())\n",
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)\n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aLAsy68DYDjH"
      },
      "outputs": [],
      "source": [
        "batch_size=128\n",
        "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "F3px9J1MYGIs"
      },
      "outputs": [],
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, images, labels):\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, images, labels): \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CqaKSKb5fjOa"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuBq4JhcfmLN",
        "outputId": "1c5ef336-ea95-4769-c8f9-79845282cbd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-EFBZFOoYK5M"
      },
      "outputs": [],
      "source": [
        "class Cifar10CnnModel(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.clip = clip_model.visual\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        xb = self.clip(xb)\n",
        "        return self.network(xb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALLHYhBNYQXL",
        "outputId": "34fe1639-ec62-4c19-c7d4-b3e3d20d6a19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cifar10CnnModel(\n",
              "  (clip): VisionTransformer(\n",
              "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (transformer): Transformer(\n",
              "      (resblocks): Sequential(\n",
              "        (0): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = Cifar10CnnModel()\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV8w0HQ5cIJD",
        "outputId": "ef4f2911-8afe-4cc7-b962-85ce51a78708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 224, 224])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# test on one image\n",
        "images_list = []\n",
        "\n",
        "image, _ = dataset[100]\n",
        "transform = T.ToPILImage()\n",
        "image = transform(image)\n",
        "image_input = preprocess(image).unsqueeze(0).to(device).squeeze()\n",
        "images_list.append(np.asarray(image_input.cpu() if torch.cuda.is_available() else image_input))\n",
        "\n",
        "image, _ = dataset[200]\n",
        "transform = T.ToPILImage()\n",
        "image = transform(image)\n",
        "image_input = preprocess(image).unsqueeze(0).to(device).squeeze()\n",
        "images_list.append(np.asarray(image_input.cpu() if torch.cuda.is_available() else image_input))\n",
        "\n",
        "images_list = np.asarray(images_list)\n",
        "images_list = torch.from_numpy(images_list)\n",
        "\n",
        "print(images_list.shape)\n",
        "\n",
        "images_list = images_list.to(device)\n",
        "model = model.to(device)\n",
        "if torch.cuda.is_available():\n",
        "  model = model.type(torch.cuda.FloatTensor)\n",
        "output = model(images_list)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVH7tzSufVrH",
        "outputId": "da65cf66-5d3e-4b6f-e7b6-4fc712b0fa01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cifar10CnnModel(\n",
              "  (clip): VisionTransformer(\n",
              "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (transformer): Transformer(\n",
              "      (resblocks): Sequential(\n",
              "        (0): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model = Cifar10CnnModel()\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0_RsclZVgn4W"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import copy\n",
        "\n",
        "transform = T.ToPILImage()\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = list()\n",
        "    for images, labels in tqdm(val_loader):\n",
        "      new_images = []\n",
        "      for i, image in enumerate(images):\n",
        "        image_input = preprocess(transform(image)).unsqueeze(0).to(device)\n",
        "        image_input = image_input.squeeze()\n",
        "        new_images.append(np.asarray(image_input.cpu()))\n",
        "      new_images = np.asarray(new_images)\n",
        "      new_images = torch.from_numpy(new_images)\n",
        "      new_images = new_images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs.append(model.validation_step(new_images, labels))\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def check_parameters(before_model, after_model):\n",
        "  params_before = before_model.state_dict()\n",
        "  params_after = after_model.state_dict()\n",
        "  total_number = 0\n",
        "  equal_number = 0\n",
        "  for key in params_before.keys():\n",
        "    if key.startswith(\"clip\"):\n",
        "      this_layer_equal = (params_before[key] == params_after[key]).sum()\n",
        "      this_layer_total = len(params_before[key])\n",
        "      if this_layer_equal == this_layer_total:\n",
        "        equal_number += 1\n",
        "      total_number += 1\n",
        "  print(total_number, equal_number)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    # Training Phase \n",
        "    model.train()\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        new_images = []\n",
        "        for i, image in enumerate(images):\n",
        "          image_input = preprocess(transform(image)).unsqueeze(0).to(device)\n",
        "          image_input = image_input.squeeze()\n",
        "          new_images.append(np.asarray(image_input.cpu()))\n",
        "        new_images = np.asarray(new_images)\n",
        "        new_images = torch.from_numpy(new_images)\n",
        "        before_model = copy.deepcopy(model)\n",
        "\n",
        "        new_images = new_images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        loss = model.training_step(new_images, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        after_model = copy.deepcopy(model)\n",
        "        check_parameters(before_model, after_model)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38c-9m0HXESc",
        "outputId": "53df9bdf-ab2d-46c2-e904-75da5eda5fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/352 [00:01<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.0001\n",
        "\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJEqAX90ZGlA"
      },
      "source": [
        "# Freeze parameters after two epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qMuqBlKtZG_o"
      },
      "outputs": [],
      "source": [
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        if epoch == 2:\n",
        "            model.clip.requires_grad_(False)\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for images, labels in tqdm(train_loader):\n",
        "            new_images = []\n",
        "            for i, image in enumerate(images):\n",
        "              image_input = preprocess(transform(image)).unsqueeze(0).to(device)\n",
        "              image_input = image_input.squeeze()\n",
        "              new_images.append(np.asarray(image_input.cpu()))\n",
        "            new_images = np.asarray(new_images)\n",
        "            new_images = torch.from_numpy(new_images)\n",
        "\n",
        "            new_images = new_images.to(device)\n",
        "            loss = model.training_step(new_images, labels)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XMZb2lIpayI",
        "outputId": "a04509e0-64fd-4d87-813a-04ea3728f16b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cifar10CnnModel(\n",
              "  (clip): VisionTransformer(\n",
              "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
              "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (transformer): Transformer(\n",
              "      (resblocks): Sequential(\n",
              "        (0): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): ResidualAttentionBlock(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): Sequential(\n",
              "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (gelu): QuickGELU()\n",
              "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model = Cifar10CnnModel()\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "to_device(model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YQ_TqFvpjzG",
        "outputId": "1919bcaa-7257-4c3d-df99-fed476dcd590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [08:08<00:00,  1.39s/it]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0], train_loss: 1.4368, val_loss: 0.9723, val_acc: 0.6529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [08:02<00:00,  1.37s/it]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], train_loss: 0.6639, val_loss: 0.5830, val_acc: 0.7951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:05<00:00,  1.43it/s]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2], train_loss: 1.0470, val_loss: 1.0797, val_acc: 0.6168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:04<00:00,  1.44it/s]\n",
            "100%|██████████| 20/20 [00:27<00:00,  1.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3], train_loss: 0.9879, val_loss: 1.0522, val_acc: 0.6235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:04<00:00,  1.44it/s]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4], train_loss: 0.9625, val_loss: 1.0403, val_acc: 0.6345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:07<00:00,  1.42it/s]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5], train_loss: 0.9437, val_loss: 1.0178, val_acc: 0.6369\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:04<00:00,  1.44it/s]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6], train_loss: 0.9278, val_loss: 1.0045, val_acc: 0.6451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:04<00:00,  1.44it/s]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7], train_loss: 0.9131, val_loss: 0.9943, val_acc: 0.6414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:04<00:00,  1.44it/s]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8], train_loss: 0.9012, val_loss: 0.9812, val_acc: 0.6498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 352/352 [04:04<00:00,  1.44it/s]\n",
            "100%|██████████| 20/20 [00:26<00:00,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9], train_loss: 0.8893, val_loss: 0.9707, val_acc: 0.6548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.0001\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model = model.type(torch.cuda.FloatTensor)\n",
        "history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cRhqBarTqUXb",
        "outputId": "0634c595-33ff-4661-89e3-85e8ea4291c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');\n",
        "\n",
        "plot_accuracies(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "sOPOyMo9qYUb",
        "outputId": "e1a8afb1-062a-49ab-df1b-1d28302d2c88"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deViU5d4H8O+wqSyyiggoy0HZRGcU3Bco01QiFyRxxSW0fCutrM4xl8wyTc+xsuVghrniUi4H1EoFNa0EBfcFFVSwZDEBF/b7/eN2hhmYGQaYhweY3+e65mL2554B5jv3LmGMMRBCCDFYRmIXgBBCiLgoCAghxMBREBBCiIGjICCEEANHQUAIIQaOgoAQQgwcBQEhTci9e/cwaNAgWFlZ4a233hK7OAAAd3d3HDp0SOxiEAFREBC9aEkfFkuWLIFEIsGOHTsU15WXl0MikSAzM1PQY8fExMDBwQGFhYVYvXq1oMciRI6CgBA17OzssHjxYlRUVDTqcW/dugU/Pz9IJJJGPS4xbBQERFAlJSWYO3cunJ2d4ezsjLlz56KkpAQAkJeXh9DQUNjY2MDOzg4DBw5EZWUlAGDFihVwcXGBlZUVvL29cfjw4RrP/ccff8DJyUnlw3r37t3o1q0bAODUqVMIDAxE27Zt0b59e7z55ps6l/v555+HmZkZNm/erPb2goICTJkyBe3atYObmxuWLVumKHttTp48iaCgIFhbWyMoKAgnT54EAERFReH777/HypUrYWlpqbaGVVJSgrfffhudOnVC+/btMXv2bDx58gQAkJSUBFdXV3z88cdwcHCAu7s7tmzZonOZ161bB19fX1hZWcHPzw9nzpxR3JaWloZu3brB2toaL730EoqLiwFo/x2SZoQRogdubm7sl19+qXH9woULWe/evdm9e/dYTk4O69u3L3v//fcZY4y99957bNasWay0tJSVlpayY8eOscrKSnblyhXm6urKsrOzGWOMZWRksOvXr6s9rqenJ/v5558Vl8PDw9ny5csZY4z16dOHbdy4kTHGWFFREfvtt990ei2LFy9mEydOZHv37mUeHh6stLSUlZWVMQAsIyODMcbY5MmTWVhYGCssLGQZGRmsc+fO7Ntvv631ufPz85mNjQ3buHEjKysrY1u3bmU2NjYsLy+PMcbY1KlT2YIFCzQ+fu7cueyFF15g+fn5rLCwkIWGhrL33nuPMcZYYmIiMzY2ZvPmzWPFxcUsKSmJmZubsytXrtRa5h07djBnZ2d26tQpVllZydLT01lmZiZjjP9ug4KCWHZ2NsvPz2c+Pj7s66+/Zoxp/h2S5oWCgOiFpiDw9PRkCQkJissHDx5kbm5ujDEeEmFhYSw9PV3lMenp6axdu3bsl19+YaWlpVqPu2DBAjZt2jTGGGOFhYXM3Nxc8QE2cOBAtmjRIpabm1un1yIPAsYY69WrF/vqq69UgqC8vJyZmpqyixcvKh7zzTffsMGDB9f63Bs3bmRBQUEq1/Xp04fFxsYyxrQHQWVlJTM3N1cJxZMnTzJ3d3fGWFUQPHz4UHH7uHHj2NKlS2st89ChQ9maNWvUHtfNzY1t2rRJcXn+/Pls1qxZjDHNv0PSvFDTEBHU3bt34ebmprjs5uaGu3fvAgDmz58PLy8vDB06FJ6envjkk08AAF5eXlizZg2WLFkCR0dHjB8/XvGY6iZMmIAff/wRJSUl+PHHH9GjRw/F8davX49r167Bx8cHQUFBiI+Pr3P5ly1bho8++kjRFALw5pCysrIarys7O7vO70ddHpubm4vHjx+jZ8+esLGxgY2NDZ5//nnk5uYq7mNrawsLCwuV5757926tZb5z5w7+8Y9/aDy2k5OT4ry5uTkePnwIQPPvkDQvFAREUM7Ozrh165bi8u3bt+Hs7AwAsLKywurVq3Hz5k3s27cP//73vxV9ARMmTMCvv/6KW7duQSKR4N1331X7/H5+fnBzc8OBAwewdetWTJgwQXFb586dsW3bNuTk5ODdd99FeHg4Hj16VKfyP/fcc/Dy8sJXX32luM7BwQGmpqY1XpeLi0ud34+6PNbBwQFt2rTBxYsX8eDBAzx48AAFBQWKD2UA+Pvvv1Veo/z9rq3MHTt2xI0bN2otQ3Xafoek+aAgIHpTVlaG4uJixam8vByRkZFYtmwZcnNzkZeXh6VLl2LSpEkAgPj4eFy/fh2MMVhbW8PY2BhGRka4evUqjhw5gpKSErRu3Rpt2rSBkZHmP9UJEybgs88+w7FjxzBu3DjF9Zs3b0Zubi6MjIxgY2MDAFqfR5OPPvoIK1euVFw2NjZGREQEFixYgKKiIty6dQv//ve/Fa9LmxEjRuDatWvYunUrysvLsX37dly6dAmhoaG1PtbIyAgvv/wy5s2bh5ycHABAdnY2fvrpJ5X7LV68GKWlpTh+/Dji4+Mxbty4Wss8c+ZMrFq1CqdPnwZjDNevX68RWOpo+h2S5oV+Y0RvRowYgTZt2ihOS5Yswfvvv4/AwEB069YNAQEB6NGjB95//30AQHp6OoYMGQJLS0v07dsXr776KkJCQlBSUoL33nsPDg4OcHJyQk5ODpYvX67xuJGRkTh69CieeeYZODg4KK4/ePAg/P39YWlpiTfeeANxcXFo06YNAMDS0hLHjx/X6XX1798fvXr1Urnuiy++gIWFBTw9PTFgwABMmDAB06dPBwB8/PHHGD58uNrnsre3R3x8PFavXg17e3usXLkS8fHxKuXWZsWKFfDy8kKfPn3Qtm1bDBkyBFevXlXc7uTkBFtbWzg7O2PixIn45ptv4OPjU2uZx40bhwULFmDChAmwsrLCqFGjcP/+/VrLo+l3SJoXCWO0MQ0hLUFSUhImTZqErKwssYtCmhmqERBCiIGjICCEEANHTUOEEGLgqEZACCEGzkTsAtSVfA0VQgghusvMzEReXp7a25pdELi7uyMlJUXsYhBCSLMSGBio8TZqGiKEEANHQUAIIQaOgoAQQgxcs+sjIIS0HGVlZcjKylJZ3ZU0TOvWreHq6gpTU1OdH0NBQAgRTVZWFqysrODu7k7bc+oBYwz5+fnIysqCh4eHzo9r8U1DK1cCiYmq1yUm8usJIeIqLi6Gvb09hYCeSCQS2Nvb17mG1eKDICgIiIioCoPERH45KEjcchFCOAoB/arP+9nim4ZCQoAdO4CxYwEfH+DaNWDnTn49IYQQA6gRAPxDf+hQ4LffgBdeoBAghHD5+fmQSqWQSqVwcnKCi4uL4nJpaanWx6akpOD111+v9Rj9+vXTV3EF0+JrBABvDvrlF35+1y5gyhQKA0Kam5UreZOu8v9uYiKQnAy88079ntPe3h5paWkAgCVLlsDS0hJvv/224vby8nKYmKj/mAwMDNQ6W1fu5MmT9StcI2rxNQJ5n8DOnYC9PTBokGqfASGkeWis/r6oqCjMnj0bvXv3xjvvvINTp06hb9++kMlk6Nevn2JHuKSkJMUWo0uWLMH06dMRHBwMT09PfP7554rns7S0VNw/ODgY4eHh8PHxwcSJEyFf/Hn//v3w8fFBz5498frrr+u0dak+tfgaQXIy7yMICQFkMuDePX45OZlqBYQ0JXPnAk+/nGvk7AwMGwZ06AD8+Sfg6wt88AE/qSOVAmvW1L0sWVlZOHnyJIyNjVFYWIjjx4/DxMQEhw4dwr/+9S/88MMPNR5z5coVJCYmoqioCN7e3njllVdqjOVPTU3FxYsX4ezsjP79++PEiRMIDAzErFmzcOzYMXh4eCAyMrLuBW6gFh8EylVGqRT44gtgwAAKAUKaI1tbHgK3bwOdOvHLQhg3bhyMjY0BAAUFBZg6dSrS09MhkUhQVlam9jEjR45Eq1at0KpVKzg6OuLevXtwdXVVuU+vXr0U10mlUmRmZsLS0hKenp6Kcf+RkZGIiYkR5oVp0OKDQJlMBpSUAFevAl27il0aQogyXb65y5uDFi4Evv4aWLxYmC91FhYWivMLFy5ESEgIdu/ejczMTAQHB6t9TKtWrRTnjY2NUV5eXq/7iEGwPoLp06fD0dERXWv5xE1OToaJiQl27dolVFEUpFL+MzVV8EMRQvRMHgI7dgBLl/KfjdHfV1BQABcXFwDAhg0b9P783t7euHnzJjIzMwEA27dv1/sxaiNYEERFReHgwYNa71NRUYF3330XQ4cOFaoYKrp0AVq3rr0dkhDS9Cj39wFVc4SSk4U97jvvvIN//vOfkMlkgnyDb9OmDb766is8//zz6NmzJ6ysrGBtba3342gj6J7FmZmZCA0NxYULF9TevmbNGpiamiI5ORmhoaEIDw+v9TkDAwMbtDFN796AhQVw5Ei9n4IQoieXL1+Gr6+v2MUQ3cOHD2FpaQnGGObMmYPOnTtj3rx59X4+de+rts9O0YaPZmdnY/fu3XjllVdqvW9MTIxizG5ubm6DjiuV8hqBcPFHCCF1s27dOkilUvj7+6OgoACzZs1q1OOLFgRz587FihUrYGRUexGio6ORkpKClJQUtGvXrkHHlUqBv/8G7txp0NMQQojezJs3D2lpabh06RK2bNkCc3PzRj2+aKOGUlJSMH78eABAXl4e9u/fDxMTE4waNUrQ48pk/GdqKh9+Rgghhk60IMjIyFCcj4qKQmhoqOAhAAABAYBEwpuHXnxR8MMRQkiTJ1gQREZGIikpCXl5eXB1dcUHH3ygmIgxe/ZsoQ5bKwsLwNubRg4RQoicYEGwbds2ne8rxNhcbaRSvhIpIYQQA1h0Th2pFLh1i3caE0IMV0hICH766SeV69asWaNxNGNwcLBiCOaIESPw4MGDGvdZsmQJVq1apfW4e/bswaVLlxSXFy1ahEOHDtW1+HpjkEEg7zCm5iFCmhEB9p2NjIxEXFycynVxcXE6Lfy2f/9+2NjY1Ou41YNg6dKlGDJkSL2eSx8MMgjkS01QEBDSjAiwDnV4eDgSEhIUm9BkZmbi7t272LZtGwIDA+Hv74/Fixerfay7uzvy8vIAAB999BG6dOmCAQMGKJapBvj8gKCgIHTv3h1jx47F48ePcfLkSezbtw/z58+HVCrFjRs3EBUVpVhm5/Dhw5DJZAgICMD06dNRUlKiON7ixYvRo0cPBAQE4MqVK/V+3dUZ1KJzco6OfDlbCgJCmhAR1qG2s7NDr169cODAAbz44ouIi4tDREQE/vWvf8HOzg4VFRV49tlnce7cOXTr1k3tc5w+fRpxcXFIS0tDeXk5evTogZ49ewIAxowZg5dffhkA8P7772P9+vV47bXXEBYWpnY1heLiYkRFReHw4cPo0qULpkyZgq+//hpz584FADg4OODMmTP46quvsGrVKnz77bfa3y8dGWSNAOB/H7T4HCHNjPI61B066GUdauXmIXmz0I4dO9CjRw/IZDJcvHhRpRmnuuPHj2P06NEwNzdH27ZtERYWprjtwoULGDhwIAICArBlyxZcvHhRa1muXr0KDw8PdOnSBQAwdepUHDt2THH7mDFjAAA9e/ZULFKnDwZZIwB4EPz8M1BczBeiI4SITKR1qF988UXMmzcPZ86cwePHj2FnZ4dVq1YhOTkZtra2iIqKQnFxcb2eOyoqCnv27EH37t2xYcMGJCUlNais8mWs9b2EtcHWCGQyoLwc0BL0hJCmRKB1qC0tLRESEoLp06cjMjIShYWFsLCwgLW1Ne7du4cDBw5offygQYOwZ88ePHnyBEVFRfjf//6nuK2oqAgdOnRAWVkZtmzZorjeysoKRUVFNZ7L29sbmZmZuH79OgBg06ZNGDx4cINeny4MNghobwJCmhkB16GOjIzE2bNnERkZie7du0Mmk8HHxwcTJkxA//79tT62R48eeOmll9C9e3cMHz4cQUqd1x9++CF69+6N/v37w8fHR3H9+PHj8emnn0Imk+HGjRuK61u3bo3Y2FiMGzcOAQEBMDIyapQJuIIuQy2Ehi5DLVdZCdjYAFOn8u0rCSGNj5ahFkazWYZabEZGQPfuVCMghBCDDQKANw+dPctrB4QQYqgMOghkMuDhQ+DmTbFLQojhamat001efd5Pgw4C6jAmRFytW7dGfn4+hYGeMMaQn5+P1nUcE2+w8wgAwN8fMDHhkxnHjRO7NIQYHldXV2RlZTV4C1pSpXXr1nB1da3TYww6CFq1Avz8qEZAiFhMTU3h4eEhdjEMnkE3DQFVm9kTQoihoiCQ8rWr7t0TuySEECIOgw8C2puAEGLoDD4IunfnPykICCGGyuCDwNYWcHenICCEGC6DDwKA9iYghBg2CgLwILh2DXj0SOySEEJI46MgAO8wZgw4d07skhBCSOOjIABtZk8IMWwUBAA6duSdxhQEhBBDREEAQCLhzUPUYUwIMUQUBE9JpcD583wfY0IIMSQUBE/JZEBxMR89RAghhoSC4Cnam4AQYqgoCJ7y9ubLUlOHMSHE0FAQPGVqCgQEUI2AEGJ4KAiUyPcmoF3zCCGGhIJAiUwG5OcD2dlil4QQQhoPBYES6jAmhBgiCgIl3brxyWXUYUwIMSQUBEosLYHOnalGQAgxLBQE1dBm9oQQQyNYEEyfPh2Ojo7o2rWr2tu3bNmCbt26ISAgAP369cPZs2eFKkqdSKVARgbw4IHYJSGEkMYhWBBERUXh4MGDGm/38PDA0aNHcf78eSxcuBDR0dFCFaVO5JvZN5FcIoQQwQkWBIMGDYKdnZ3G2/v16wdbW1sAQJ8+fZCVlSVUUeqE9iYghBgaE7ELAADr16/H8OHDNd4eExODmJgYAEBubq6gZXFy4icKAkKIoRA9CBITE7F+/Xr8+uuvGu8THR2taDoKDAwUvEy0mT0hxJCIOmro3LlzmDlzJvbu3Qt7e3sxi6JCKgUuXQJKS8UuCSGECE+0ILh9+zbGjBmDTZs2oUuXLmIVQy2ZDCgrAy5eFLskhBAiPMGahiIjI5GUlIS8vDy4urrigw8+QFlZGQBg9uzZWLp0KfLz8/Hqq6/ygpiYICUlRaji1Ilyh7F8FBEhhLRUggXBtm3btN7+7bff4ttvvxXq8A3i5QVYWFCHMSHEMNDMYjWMjIDu3anDmBBiGCgINJAvNVFZKXZJCCFEWBQEGshkQFERkJkpdkkIIURYFAQa0N4EhBBDQUGgQdeugLExdRgTQlo+CgINWrcGfH2pRkAIafkoCLSgvQkIIYaAgkALmYxvZC/wOneEECIqCgItaElqQoghoCDQgoKAEGIIKAi0sLMDOnWiDmNCSMtGQVAL6jAmhLR0FAS1kEqBq1eBx4/FLgkhhAiDgqAWMhlfb+j8ebFLQgghwqAgqAV1GBNCWjoKglq4uQE2NhQEhJCWi4KgFhIJbWZPCGnZKAh0IJUC584BFRVil4QQQvSPgkAHMhnw5Alw7ZrYJSGEEP2jINBBi+owXrkSSExUvS4xkV9PCDFIFAQ68PUFzMxaSBAEBQEREVVhkJjILwcFiVsuQohoTMQuQHNgaso3qmkRHcYhIcCOHcALL/A1NHJzgTlzACsroLiYb8RACDEoVCPQkXypCcbELokeBAfz4VB37vDZcqtX8xqBpSVPvEmTgFWrgMOHgbw8sUtLCBEY1Qh0JJMB330H/Pkn4OwsdmkaKCYGePgQePFF4MQJYM0aoE0bnnSpqcDRo8CWLVX3d3XlSSiV8jdCKgU8PHiYEEKaPQoCHSlvZt+sgyAxEXjzTX5+3TrgwgXeR7BjB7B0adX98vKAs2d5OMgD4sCBqjG0bdsC3burBoSfH9CqVeO/JkJIg1AQ6KhbN/4zLQ0YOVLcsjRIcjJfW9vaGmjXrqrPIDmZn5dzcACefZaf5J48AS5erAqHtDQgNpbXLgDAxISHgTwcpFIeFnZ2NcuxciVvjlI+ZmIiL8c77wjz2gkhalEQ6KhtW8DLq/l3GK8tmoo5V9+DROnbfyJCkIwQ1Prx26YNEBjIT3KVlcCNG6rhcOgQsHFj1X3c3FTDQSrlzyGviYSEVI1e2rFDr6+XEFI7CoI6aAlLTTxbegASxpDsOBJB0MPnr5ER0LkzP40bV3X9vXuqTUtpacD//seDA+ALOLm58erVoEHAyZPAokW89nD3Lq+RmJk19OUSQnRAQVAHUimwaxdQWMhrCM2R780ElNg7Y/g/pZh0ifcJy7+U61X79sDQofwk9/gxX89bORzKyoCffuK3z5+v+hxt2/LmK20nB4eq8xYWdS8nNVERQkFQFzIZ/3n2LDBwoLhlqZeyMuDnn9EqIgJWhyT47DM++Of+fX6TqanAxzc3B3r35iegqjoydSofkrVoEdCxI5/bkJvLO6zl52/fBk6f5ufLytQ/f5s22oOi+snaumqCHTVREQNGQVAHyktNNMsg+PVXoLAQSZahyMwE3N2BW7eA8HDAyQmYMQN4+WXeYiM45Q/ckBDeRCS/PHas5scxxqtk1YOi+ikvD7hyhZ9/9Ej9c5ma8qCwsgKGDeNzKK5dAxYs4IFUXs47wAlp4SSMNa8pUoGBgUhJSRHl2IzxD8yRI/kX2GbnrbdQ+cVaOJnkI6/YErdv88/KsWP5YJ9Tp/hrHD4cmDULGDFCwM/BxmySefJEfVAoX05JAbKzVR9nasr7Pry9AR8f/lN+srXVbxkJEZi2z06dguCzzz7DtGnTYGVlhZkzZyI1NRWffPIJhiq3/zYSMYMA4F8cc3OBM2dEK0L9+fjgZqUbev/9EwID+bQAoOrzd/x44Ntv+enPP/k8spkz+cnFRdyiC0peO3nlFeCrr4AlS3h/w9Wr/HTlCnD9Oq8hyDk6qoaD/Ly7O9UiSJOk9bOT6aBbt26MMcYOHjzIRo8ezS5cuMBkMpkuD9W7nj17inJcuXfeYczMjLGSElGLUXfp6YwB7NKrnzOAsR07NN+1tJSxH39kbNgwxgDGjI0ZGzWKsQMHGKuoaLwiN4ojRxhzcOA/1V2WKy1l7OpVxvbtY+zTTxmbMYOxAQP4fXlFip/MzBjz82Ns9GjG/vlPxjZsYOz33xn7+2/t5VixouYxjxzh1xOiB9o+O3X66sKeVhr279+PyZMnw9/fX3GdoZHJgNJS4PJlPleq2UhIAAB8fWsk7OyAsDDNdzU1BUaP5qebN/kE5PXrgT17+Bfe6Ghg+nQ+MKjZS05WHTalaYKdqSnQpQs/vfCC6nPk51fVHuQ1iMuX+XBZ5VpE+/Y1axA+PvxNpU5rIiKdmoamTZuG7OxsZGRk4OzZs6ioqEBwcDBOnz7dGGVUIXbT0JUrfFnqDRv4YJdmY+hQVGTegfmty5g1C/j887o9vLSUB8E33/DPKBMTHhSzZvHPLSNavrCmsjIgI4P/0SiHxNWrqov5mZnx2Yr29ryvQj6vYulS3mHj5MSH0tLaTqQBGtxHUFlZibS0NHh6esLGxgb3799HVlYWusnXXWhEYgdBRQX/n4yOBv7zH9GKUTcPHwL29kgd8Bp6HFmF1NSqEVD1ce0aX7cuNpYPPe3cmb8fUVF8EA7RgXItQh4OV67wN1fdv2SrVjwQ2rfnJ3Xn5T+trOoXGjSnokVrcBCcOHECUqkUFhYW2Lx5M86cOYM33ngDblrGGU6fPh3x8fFwdHTEhQsXatzOGMMbb7yB/fv3w9zcHBs2bECPHj0a9GIaS9++/P8yKUnUYuhuzx5g9GhEd05EimWw3jq6i4uBH37gtYRff+VfbMPDgdmzgQED6Atsncmbg6ZM4Sn7r38BHToAf/3FZ2rLf8rP5+ZWzdRW1rp1zXDQdN7SsuoXVX1Ib/XLpFlrcGdxQEAAq6ysZGlpaUwqlbK1a9eyQYMGaX3M0aNH2enTp5m/v7/a2xMSEtjzzz/PKisr2W+//cZ69eqlS1FE7yxmjLHZsxmztmasslLskuhoxgxWbmnNTFDKPv9cmENcuMDYa6/x9wVgzNeXsTVrGLt/X5jjtTi6dlorKy9n7K+/GDt7lrGff2Zs40bekf3WW4xNmsTYc88xFhDAmKMjYxKJaqe2/GRuzpiHB2N9+vARAaGh/LrhwxmzsuKd1cnJjN24wTu8W9xoAcOh7bNTpxpBjx49cObMGSxduhQuLi6YMWOG4jptMjMzERoaqrZGMGvWLAQHByMyMhIA4O3tjaSkJHTo0KH+qdZIYmJ42/jNm3xmbpPGGODiglTLAehzawfu3uVN0UJ5/BjYvh3473+BP/7gX05feonXEnr3plqCRkI3y5SX834J5ZpF9RqG/Ke2zYiMjPgcCju7midN18tv03VYLTVRCULbZ6dOvxkrKyssX74cmzZtwvHjx1FZWYkyTdP8dZSdnY2OHTsqLru6uiI7O1ttEMTExCAmJgYAkJub26Dj6oPyDOMmHwSpqcCff+Jbi5F48UVhQwDgq0hMm8ZPaWk8EDZvBr7/ni/lPXs2MHEib06i/3Ul6l50SIj+mmRMTHhzkJOT9uFu8uagyZP5iIglS/iopr//5h1C1U+5ubx/4/594MED7WVo21a38DAz47Mc//tfPrzt5EkaQSUwnYJg+/bt2Lp1K7777js4OTnh9u3bmF99gTABRUdHIzo6GgBPNbF17cq/GKWl8ZEzTVp8PJhEgp2PhmPj9MY9tFQKfP01/4K3bRv/8H/1Vb62XHAwsHw58OOPNFqyyajeJ/DCC1WXtY03lquo4GFw/77m4FA+3blTdV6+4ZGyiAj+UyLhMxoXLwa+/LKqn0PdqT4LDxLdgsDJyQkTJ05EcnIy4uPj0atXL0yZMqVBB3ZxccGdO3cUl7OysuDSTKavmpvz4d/NYknqhARcte4FMwtHPPecOEWwsuKjil5+mY+O/O9/eTA8fswXJ+3fn7+XX34JDB4sThkJdJ9ToYmxMa9y1rXayRgf2VY9KDZsAPbv53tXeHjwpquLF4EjR3jQqGNurj0o2rfns8Lbt+eLDmprqzSgJiqdgmDHjh2YP38+goODwRjDa6+9hk8//RTh4eH1PnBYWBjWrl2L8ePH448//oC1tXWt/QNNiVQKHD8udilqkZMDlpyMrfgAU1/l/6dikkj4/1VQELB6NW8y+vBDvkUywFsjZs3i6x4FBPCaV0AAP7VvT/0LghO6eUoTiYR/W7CyqlrxMDGRL361cCGvVq5YoVqO0lLeLCXv46h+ysuaiSIAABxBSURBVMnhnXi//cbvp2lIrjwU1IWFsTFvovruO14jOnq0xVZbdQqCjz76CMnJyXB0dATA2+mHDBmiNQgiIyORlJSEvLw8uLq64oMPPlD0K8yePRsjRozA/v374eXlBXNzc8TGxurh5aghUKrLZMDWrXw4uNDt7vV2gG9C8z+EYuc0sQujytqaf+BXVADvvstrCTNn8j7N8+f5F0HlPwl7e9Vw6NqVn5rrvhBEi+pNVCEhNYexmpnx5iJdWhEqKqo6yuUhUT047t7l1dKcHNXZ4EBV+69Ewjcs/+c/+R+kvE9D3Xn5z7ZtGz7bshFqJjoFQWVlpSIEAMDe3h6V6sYvK9m2bZvW2yUSCb788ktdDt8wylP3g4L4m6eHVFfuMFbe1rcpYfHxyDF2hlVfKby8xC6Nqur/68OGVV2WT9TLzeWhcOFC1c8NG6q2SAb4F0jlcAgI4Cs3tGolyssi+tDQJqrqjI2rvunXhjHe7KQcErGxfPOknj357Mn8fB4Yly/zJqyCAs3PZ2Sk2hFePSg0nVeeSd4Iy4/oNHx0/vz5OHfunGKo5/bt29GtWzesWLFCbwXRVb2GjyYmAi++yJcjbtuWbzPWwOpuXh7f22TVKuCttxr0VMIoK0O5rQNiH0XANHYdoqLELpCq+n7Jqazke9ScP68aEleuVH2RMzHhSwJVr0F4eNT8cmZAzcCkPpRXpv36a/WT68rLqzrH8/Or+jjk5zVdV1Sk+bjGxqrhUFnJaywvvMBnstZjkl+DZxYDwA8//IATJ04AAAYOHIjRIg2Xqfc8gtdfB774gg9XSUzUS1k6duSdm5s36+Xp9CsxEXjmGUS23o11uaNgaSl2gYRVWspXZ5AHgzwkMjKq7mNuDvj7qwZEQQEf0kqTaUkNQs+0LivjAVJbYMivu3GDb8q0cCFfh6qOGjyzuCmp18xi+SxNNzfGjIwYO3xYL2UJDWVMw8Rp0ZX835usGGbslclFYhdFVIWFfBXodesYe+MNxp55hrF27VQn17Zty5ipKWMyGZ9U+/77/DH37jWj2eNE/5rS0uDyz7CFC2ufca5BvWcWW1lZQaJmqAZjDBKJBIWFhXVOpYaqc41AOcVv3+Yro9nYVA1gb4CFC/lY+KIivl1uU1LQwQe//+UGy19/Qv/+Ypem6cnJUW1aOniw5gZlAB+W7u7Om5XUnaizmghOTzWTes8sLtLWhtVcKHc8PXwIzJkD9OtX/44nJTIZH5Bw4QJvZ24ybtyA9V9XkdzuVSzoJ3ZhmiZHR97J/+yz/P9q714e7F99xfsN2rXjzUrKp6NHazbr2tlVhUL1wHB350ts6IL6KohG+u48V6Pl76mn/F9kaQmMG8eXzNy5s8FPrTxyqCkFQc6GBDgCcJg6ksbe10LbSMXXX1e9L2O8qbZ6QGRkAOfOAfv28b4KZR06aK5NuLpWLb9D+9IQjRphfkfLD4LqoqL4GMTdu/miNw0gbxpoajOMC7bEIx8+CJv3D7GL0uTV5cuWRFI1cVbdSieVlXyvZ3VBcfw4n02tPOraxIQPOJAHQ1gYH9w2Zgzf3GzrVuqwJo1D51FDTUWDVx+trOS7Qf3jH8AvvzS4PIMH887/kycb/FR6UVHwEOU29kjweA1jbq4SuzhESVkZ76ZSFxQZGbzforp27XjNofrJxaXqPC2vQ3TR4NVHWxQjI14rWLKE/1d26tSgp5NK+X6+FRXiL+EAAGmrDqEnSuEwdaTYRSHVmJry7x//0FBR278fmDSJ7065bx/f5MfMDMjKAm7dAk6c4E1T1dnYaA4J+am2ZXUA6qcwZIYXBADfAWrxYmDTJmDBggY9lUwGPHoEXL/OZ7SK7cGWeBRK2qLP2wPELgqpg8REvgf2Dz9oHxjy+DFfDSErq+YpO5v3V927V3NpHQsLzSEhPwUGUj+FoTLMIHB353/pGzbw7QAb0KOq3GEsdhDk5zH4ZuzHjc7DILMwFbcwpE507aswN+ctm9qWDCkt5X0V1UNCfj4xkYdJ9ZWfzcz4KKihQ/nf8s2bPJz++ouPmHJ25idqimp5DDMIAN48NHUqb9xvwEB7Pz9e5U9L4ztxiemXlakYjz9RPpmahZobfQ4MMTPjazBp2VIcFRW85lA9JLKy+P7TFy/yzuxvvuEnZW3b8tFQ8mBQPsmv79CBh1Z9UBNV4zPcIBg7ls8piI1tUBCYmfFlC5rCyKH7mxJQCQk6zRoudlFIE2dsXPXhrSwxEfj556rVn7/7jvdp/Pknr0Uon/78k3+PunsXKCmpeQwbm5oBUT00OnSoOdeChtI2PsMNAgsLPqdgxw7gs88aVN+VSoEDB/RYtnpITQV6/hWPHPdecFJaKZYQXWmbU6FthV35gp3ycFAXGMeO8fPqdri1s6sZEJGRwKhRfCjt3r18q9PgYMFeusEz3CAAePNQbCyfUzBpUr2fRibj3Q1//sn/iMWw88scLEMyiiM/EKcApNmr7wRWiaRqocyuXTXfjzG+hpq2wLh8mf+UryS7YQP/GRbGm6ocHPiQ2nbtVM+ru87evmrCXn0YUhOVYQfBgAGApyf/a2tAECh3GIsRBCUlQEHcARiBwTyc+gdI/Qg9gVUi4R/UDg5At26a71dZCezZA8yYwYfSxsfzf08bG75HRW4uXwY+LY2f17RrJQDY2moOCnWXldcMM6QmKsMOAiMj3mG8ZAkfqK2td02L7t35z7Q0/ofb2PbtA4IfxaPY3hmtZbLGLwAhenT0KN+yVL4uZG1rrJWV8ZpGXl5VUMjDQvny9evA77/z66tvQiZnbq4aDDIZMHIk0Lcv3znz3Xd5n8b16zxEdJmf0RwYdhAAqnMK3n+/Xk9hbc0rFmJ1GH//bRm2Sn6G2aiIlvFXSQxaXZuoTE0BJyd+0gVjwIMH6sNC+bqcHP6zrAw4coQ/duFCflI+tromKk01Dju7uk88bYwmKgoC5TkFCxbU+4NUKuU1gsaWlQU8/vlXtEUhEErNQqT5a4wmKltbfurSRft95bWRmTOBmBjgo494w0H18JAHSEoKP69p90r5zpXawqL6bY3RREVBAFTNKThxgvcb1INMxvuci4oAKyv9Fk+bjRuBEUgAMzWDZMiQxjswIS1c9SapoUOrLk+Zov2xpaXaaxvy06VL/Gd+fs3Z4HLW1nxQ49ChfG/vP/7Q/w56FARA1ZyCDRvqHQRSKf9FnjvXoGkJdcIYH+d9pE08JAOD0eL3oySkETVkGwAzM/XzNDSpqODrSGlqrsrN5f0bCQm8aUrfq9JSEAB6mVOgPHKosYLg+HGA3biBTrgKjHy1cQ5KiIFohG0AFIyNq5qD1ElMBA4dqprop+9yGOnvqZq5qCjerrN7d70e7uLC2/Mas8M4NhYY2yqBXxhJ/QOEtETKTVRLl/KfERH8en2hIJAbOLBqTkE9SCSN22FcVMT/IKY6xPMVwjStbUwIada0NVHpCwWBnETCawVHjvA5BfUglfL9i9VNo9e3nTsByeOH8M05CoSGCn9AQogo3nmnZjNQSIh+ZzdTECibMoX3wG7aVK+Hy2R8lu+VK3oulxrffQdEuRyCUVkpNQsRQhqEgkCZmxvwzDO8eageO3gqdxgL6epVPtL1ZecEviZwPUc6EUIIQEFQU1QUcOMGX5S9jry9+VolQncYb9gAGBsxdL2dwAcWm9ImNISQ+qMgqG7MGD4evx6dxsbGQECAsDWC8nK+JO//9U+F8b0/qVmIENJgFATVWVhUjdV69KjOD5ePHKpHy5JOfvqJL9Mb7ZLAO7jFWOWOENKiUBCoExUFPHzIlz+sI5mML4t7+7b+iwXwuQPt2gE+N+L5IiS0CQ0hpIEoCNRR3qegjoTsMM7L40tOzx6TA6OUZBo2SgjRCwoCdRowpyAggD9ciCDYsoXPUYjueIC3PVH/ACFEDygINJEvL7hxY50eZmHBRw/pe+QQY8D69UBgIOB6NoFvhUab0BBC9ICCQJMGzCkQYqmJM2eA8+eBmVPLeI/xiBG0CQ0hRC8oCLSJigJu3qzznAKZjLco3b+vv6LExvIt8ia6/QoUFlL/ACFEbygItBkzhu8yU8dOY3mH8dmz+ilGcTHvHxg9GrA8msAXO6dNaAghekJBoE095xToe+TQnj18j9Xp0wHExwODB9MmNIQQvRE0CA4ePAhvb294eXnhk08+qXH77du3ERISAplMhm7dumH//v1CFqd+6jGnwNGR70ykrw7j2FigUyfgGbcbfKEhahYihOiRYEFQUVGBOXPm4MCBA7h06RK2bduGS5cuqdxn2bJliIiIQGpqKuLi4vDqq01wl63+/fla//VoHtJHjeD2beCXX3geGR2gTWgIIfonWBCcOnUKXl5e8PT0hJmZGcaPH4+9e/eq3EcikaCwsBAAUFBQAGddN/hsTPWcUyCVApcv8/b9hti4kQ9aiooC37CUNqEhhOiZYEGQnZ2Njh07Ki67uroiOztb5T5LlizB5s2b4erqihEjRuCLL75Q+1wxMTEIDAxEYGAgcnNzhSqyZlOm8ECow5wCmYwvEHfxYv0PW1nJm4VCQgCPdg+BpCSqDRBC9E7UzuJt27YhKioKWVlZ2L9/PyZPnozKysoa94uOjkZKSgpSUlLQTtPuzkLq1KlqToGa8qmjjw7jY8f46NXp08F3ri4tpf4BQojeCRYELi4uuHPnjuJyVlYWXFxcVO6zfv16REREAAD69u2L4uJi5OXlCVWkhqnjnAJPTz7ytCEdxrGxfN+ZMWPAm4VoExpCiAAEC4KgoCCkp6cjIyMDpaWliIuLQ1hYmMp9OnXqhMOHDwMALl++jOLiYnG+8eti9Og6zSkwMgK6d69/jaCwkO9LPH48YN6G8SAYOpQ2oSGE6J1gQWBiYoK1a9di2LBh8PX1RUREBPz9/bFo0SLs27cPALB69WqsW7cO3bt3R2RkJDZs2ABJU102QXlOwcOHOj1EKuWTynRsTVKxfTvw5MnTZqHUVL4JAfUPEEIEIGFMqC1UhBEYGIiUlBRxDv7rr8DAgXyLMPmidFp89x0wYwZw7RrQuXPdDtWvH59EdvEiIFn2IbB4MQ+D9u3rWXhCiCHT9tlJM4vroo5zCurbYXz5MvDbb7w2IJGANwsFBVEIEEIEQUFQF/I5BYmJQGZmrXf39wdMTOreYbxhA9//ePJkADk5wKlT1CxECBEMBUFd1WFOQatWgJ9f3WoEZWW85WnkyKcVgANPN6GhYaOEEIFQENRVHecU1HWpiYMHgXv3nnYSA7xZiDahIYQIiIKgPqKigIwMneYUyGS8j/fePd2eOjaWL1o3YgR49YA2oSGECIyCoD7qsE9BXTqMc3KA//2P9w2YmoIHTWEh9Q8QQgRFQVAf5ubASy/pNKege3f+U5cg2LKFr080bdrTKxJoExpCiPAoCOorKopvVlPLPgW2toC7e+0jh+Sb0/fqxUcbAeBBMHgwr30QQohAKAjqq18/wMtL5+ah2moEKSl88piik/jGDeDKFWoWIoQIjoKgvuowp0Am47OLtbUiyTenHz/+6RUJtAkNIaRxUBA0xOTJPBC+/17r3aRS3vRz/rz62588AbZuBcaOBaytn14p34TGy0u/ZSaEkGooCBqiUyfg2Wd5EGiZU1DbyKHdu4GCAqVmoYe0CQ0hpPFQEDSUfE7B8eMa79KxI2Bnp7nDODaWdygHBz+9Qr4JDQUBIaQRUBA0lA77FEgkmjuMb90CDh9+ujm9/LdBm9AQQhoRBUFDyecU7NyptTdYKuV9BOXlqtfLuxeiop5ewZQ2oTEzE6TIhBCijIJAH+RzCn74QeNdZDKguBi4erXqOvnm9M88A7i5Pb2SNqEhhDQyCgJ90GFOgboO46QkPvJU0UkMVA0bHT5cz4UkhBD1KAj0QT6nICmJdxyr4ePDl6VW7jCOjeXDRUePVrpjQgKfXkyb0BBCGgkFgb7Usk+BiQkQEFBVIygoAHbtAiIjgTZtnt6JNqEhhIiAgkBfOnbki8NpmVMgHznEGBAXx/sMVJqF5JvQUBAQQhoRBYE+1TKnQCYD8vOBrCzeLOTvDwQGKt0hIQFwcqJNaAghjYqCQJ9GjeLj/zV0Gss7jLduBf74Q2lzeqBqE5qRI5UmFBBCiPDoE0eftMwpWLkSePCAf/B/9BHvM3B359cDoE1oCCGioSDQNw1zCoKCgKlTARcXoKgI6N0bmDWLXw+ANwuZmtImNISQRkdBoG99+wKdO/NOACUhIXxDs9xcfvn8eX45JOTpHRIS+GJDtAkNIaSRURDom3xOwdGjwM2bKjeFhFS1/Pzf/ymFAG1CQwgREQWBEOT7FFSbU5CYCBw7BixcCMTE8MsAaBMaQoioKAiEoGZOQWIiEBHBm4OWLuU/IyKehkFCAtClC21CQwgRBQWBUKKi+EJCx44BAJKTVfsE5H0Gab8+3YQmNFSskhJCDJyJ2AVosZTnFAQH4513at4lJAQIKaBNaAgh4qIagVDkcwp27dK+a31CAh8pRJvQEEJEQkEgJPmcgl271N/OGLB/PzBsGG1CQwgRDQWBkORzCjTtU5CWBty9S81ChBBRURAIScucAgBAfDz/SZvQEEJEREEgNG37FCQk8DUmaBMaQoiIKAiE5uoKPPdczX0K5JvQ0LBRQojIKAgaQ7U5BQBoExpCSJMhaBAcPHgQ3t7e8PLywieffKL2Pjt27ICfnx/8/f0xYcIEIYsjHnX7FNAmNISQJkKwCWUVFRWYM2cOfvnlF7i6uiIoKAhhYWHw8/NT3Cc9PR3Lly/HiRMnYGtri5ycHKGKI642bYDx44EtW4C1a/ku9j/9BISH0yY0hBDRCfYpdOrUKXh5ecHT0xNmZmYYP3489u7dq3KfdevWYc6cObC1tQUAODo6ClUc8cnnFOzcCZw4wTehof4BQkgTIFgQZGdno2PHjorLrq6uyM7OVrnPtWvXcO3aNfTv3x99+vTBwYMH1T5XTEwMAgMDERgYiFz5gv7NTZ8+fGG5DRv4sFHahIYQ0kSIutZQeXk50tPTkZSUhKysLAwaNAjnz5+HjY2Nyv2io6MRHR0NAAhU2e29Gfn0U2DgQGD9euDqVWDwYCAlha9Gp24hIkIIaSSC1QhcXFxw584dxeWsrCy4uLio3MfV1RVhYWEwNTWFh4cHunTpgvT0dKGKJK6gIGD3bn7+3j3A25uvQ63Yq5IQQsQhWBAEBQUhPT0dGRkZKC0tRVxcHMLCwlTuM2rUKCQlJQEA8vLycO3aNXh6egpVJHGFhPA1h0xN+eWtW6vtVUkIIeIQLAhMTEywdu1aDBs2DL6+voiIiIC/vz8WLVqEffv2AQCGDRsGe3t7+Pn5ISQkBJ9++ins7e2FKpL4QkL4TGOg2l6VhBAiHgljjIldiLoIDAxESkqK2MWoH/k2Za+8Anz9NdUICCGNRttnJw1ibyxa96okhBDxUBA0Fk17VSYni1suQojBo60qG4vGvSqpaYgQIi6qERBCiIGjICCEEANHQUAIIQaOgoAQQgwcBQEhhBi4ZjehzMHBAe7u7vV6bG5uLtq1a6ffAjVj9H6oovejCr0XqlrC+5GZmYm8vDy1tzW7IGiIZj0rWQD0fqii96MKvReqWvr7QU1DhBBi4CgICCHEwBkvWbJkidiFaEw9e/YUuwhNCr0fquj9qELvhaqW/H4YVB8BIYSQmqhpiBBCDBwFASGEGDiDCYKDBw/C29sbXl5e+OSTT8Qujqju3LmDkJAQ+Pn5wd/fH5999pnYRRJdRUUFZDIZQkNDxS6K6B48eIDw8HD4+PjA19cXv/32m9hFEs1//vMf+Pv7o2vXroiMjERxcbHYRRKEQQRBRUUF5syZgwMHDuDSpUvYtm0bLl26JHaxRGNiYoLVq1fj0qVL+P333/Hll18a9PsBAJ999hl8fX3FLkaT8MYbb+D555/HlStXcPbsWYN9X7Kzs/H5558jJSUFFy5cQEVFBeLi4sQuliAMIghOnToFLy8veHp6wszMDOPHj8fevXvFLpZoOnTogB49egAArKys4Ovri+zsbJFLJZ6srCwkJCRg5syZYhdFdAUFBTh27BhmzJgBADAzM4ONjY3IpRJPeXk5njx5gvLycjx+/BjOzs5iF0kQBhEE2dnZ6Nixo+Kyq6urQX/wKcvMzERqaip69+4tdlFEM3fuXKxcuRJGRgbx76BVRkYG2rVrh2nTpkEmk2HmzJl49OiR2MUShYuLC95++2106tQJHTp0gLW1NYYOHSp2sQRBf/kG7OHDhxg7dizWrFmDtm3bil0cUcTHx8PR0bFFjxGvi/Lycpw5cwavvPIKUlNTYWFhYbB9an///Tf27t2LjIwM3L17F48ePcLmzZvFLpYgDCIIXFxccOfOHcXlrKwsuLi4iFgi8ZWVlWHs2LGYOHEixowZI3ZxRHPixAns27cP7u7uGD9+PI4cOYJJkyaJXSzRuLq6wtXVVVFDDA8Px5kzZ0QulTgOHToEDw8PtGvXDqamphgzZgxOnjwpdrEEYRBBEBQUhPT0dGRkZKC0tBRxcXEICwsTu1iiYYxhxowZ8PX1xZtvvil2cUS1fPlyZGVlITMzE3FxcXjmmWda7Lc+XTg5OaFjx464evUqAODw4cPw8/MTuVTi6NSpE37//Xc8fvwYjDEcPny4xXacG8Tm9SYmJli7di2GDRuGiooKTJ8+Hf7+/mIXSzQnTpzApk2bEBAQAKlUCgD4+OOPMWLECJFLRpqCL774AhMnTkRpaSk8PT0RGxsrdpFE0bt3b4SHh6NHjx4wMTGBTCZDdHS02MUSBC0xQQghBs4gmoYIIYRoRkFACCEGjoKAEEIMHAUBIYQYOAoCQggxcBQEhDSipKQkWuGUNDkUBIQQYuAoCAhRY/PmzejVqxekUilmzZqFiooKWFpaYt68efD398ezzz6L3NxcAEBaWhr69OmDbt26YfTo0fj7778BANevX8eQIUPQvXt39OjRAzdu3ADA13iSr/c/ceJE0FQeIjYKAkKquXz5MrZv344TJ04gLS0NxsbG2LJlCx49eoTAwEBcvHgRgwcPxgcffAAAmDJlClasWIFz584hICBAcf3EiRMxZ84cnD17FidPnkSHDh0AAKmpqVizZg0uXbqEmzdv4sSJE6K9VkIAA1ligpC6OHz4ME6fPo2goCAAwJMnT+Do6AgjIyO89NJLAIBJkyZhzJgxKCgowIMHDzB48GAAwNSpUzFu3DgUFRUhOzsbo0ePBgC0bt1a8fy9evWCq6srAEAqlSIzMxMDBgxozJdIiAoKAkKqYYxh6tSpWL58ucr1H374ocpliURSr+dv1aqV4ryxsTHKy8vr9TyE6As1DRFSzbPPPotdu3YhJycHAHD//n3cunULlZWV2LVrFwBg69atGDBgAKytrWFra4vjx48DADZt2oTBgwfDysoKrq6u2LNnDwCgpKQEjx8/FucFEVILqhEQUo2fnx+WLVuGoUOHorKyEqampvjyyy9hYWGBU6dOYdmyZXB0dMT27dsBAN9//z1mz56Nx48fq6zWuWnTJsyaNQuLFi2Cqakpdu7cKebLIkQjWn2UEB1ZWlri4cOHYheDEL2jpiFCCDFwVCMghBADRzUCQggxcBQEhBBi4CgICCHEwFEQEEKIgaMgIIQQA/f/YU3tLpdo1nwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "\n",
        "plot_losses(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvqKQFHWqblo",
        "outputId": "0e912914-6042-4332-9884-fe0e6e3f2160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [00:53<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 0.9735230803489685, 'val_acc': 0.659375011920929}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())\n",
        "test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\n",
        "result = evaluate(model, test_loader)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIzVucmVqjTw",
        "outputId": "130f6074-7516-4119-db28-51e0f147c312"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "torch.save(model.state_dict(), 'cifar10-cnn.pth')\n",
        "model2 = to_device(Cifar10CnnModel(), device)\n",
        "model2.load_state_dict(torch.load('cifar10-cnn.pth'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}